# AI Content Detection System - Complete Project Guide

## üìã Table of Contents
1. [Project Overview](#project-overview)
2. [System Requirements](#system-requirements)
3. [Desktop Installation & Setup](#desktop-installation--setup)
4. [Running the Application](#running-the-application)
5. [Deployment Guide](#deployment-guide)
6. [File Structure & Functionality](#file-structure--functionality)
7. [API Documentation](#api-documentation)
8. [Configuration](#configuration)
9. [Troubleshooting](#troubleshooting)
10. [Development Guide](#development-guide)

## üéØ Project Overview

The AI Content Detection System is a comprehensive solution designed to detect AI-generated content in both text and images. It combines multiple machine learning models to provide high-accuracy detection with low latency, suitable for production deployment.

### Key Features:
- **Text Detection**: Identifies content generated by GPT-3/4, Claude, Mistral, and other language models
- **Image Detection**: Detects images created by DALL¬∑E, MidJourney, Stable Diffusion, and other generative models
- **Dual Interface**: FastAPI REST API + Streamlit Web UI
- **Production Ready**: Docker containerization, health checks, logging
- **High Performance**: ‚â•90% F1 Score, ‚â§500ms latency target

### Architecture:
```
[User Input] ‚Üí [Preprocessing] ‚Üí [Inference Engine] ‚Üí [Postprocessing] ‚Üí [Output]
                                     ‚îú‚îÄ‚îÄ Text Detector (RoBERTa + Perplexity + Burstiness)
                                     ‚îî‚îÄ‚îÄ Image Detector (EfficientNet + Frequency CNN + PRNU)
```

## üíª System Requirements

### Minimum Requirements:
- **OS**: Linux, macOS, or Windows 10+
- **Python**: 3.10 or higher
- **RAM**: 8GB (16GB recommended)
- **Storage**: 5GB free space
- **Internet**: Required for initial model downloads

### Recommended Requirements:
- **CPU**: 8+ cores
- **GPU**: NVIDIA GPU with 4GB+ VRAM (optional but recommended)
- **RAM**: 16GB+
- **Storage**: 10GB+ SSD

### Dependencies:
- PyTorch 2.0+
- Transformers 4.30+
- FastAPI 0.100+
- Streamlit 1.25+
- OpenCV 4.7+
- PIL/Pillow 9.5+

## üöÄ Desktop Installation & Setup

### 1. Clone the Repository
```bash
git clone <repository-url>
cd ai_content_detector
```

### 2. Create Virtual Environment
```bash
# Using venv
python -m venv ai_detector_env
source ai_detector_env/bin/activate  # On Windows: ai_detector_env\Scripts\activate

# Or using conda
conda create -n ai_detector python=3.10
conda activate ai_detector
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Create Required Directories
```bash
mkdir -p models data logs cache
```

### 5. Download Pre-trained Models (Optional)
```bash
# If you have pre-trained models, place them in the models/ directory
# The system will download default models automatically on first run
```

### 6. Configure Environment
```bash
# Copy and edit configuration if needed
cp config/config.yaml config/config_local.yaml
# Edit config_local.yaml with your preferences
```

## üéÆ Running the Application

### Option 1: Run API Server Only
```bash
# Start the FastAPI server
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload

# API will be available at:
# - Main API: http://localhost:8000
# - Interactive Docs: http://localhost:8000/docs
# - ReDoc: http://localhost:8000/redoc
```

### Option 2: Run Streamlit UI Only
```bash
# Start the Streamlit web interface
streamlit run ui/app.py

# UI will be available at: http://localhost:8501
```

### Option 3: Run Both (Recommended)
```bash
# Terminal 1 - Start API server
uvicorn api.main:app --host 0.0.0.0 --port 8000

# Terminal 2 - Start UI (in a new terminal)
streamlit run ui/app.py
```

### Option 4: Run Demo Script
```bash
# Quick demo with sample inputs
python scripts/demo.py
```

## üê≥ Deployment Guide

### Docker Deployment

#### Single Container (API Only)
```bash
# Build the image
docker build -t ai-content-detector .

# Run the container
docker run -p 8000:8000 ai-content-detector

# With GPU support (if available)
docker run --gpus all -p 8000:8000 ai-content-detector
```

#### Docker Compose (Full Stack)
```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Services will be available at:
# - API: http://localhost:8000
# - UI: http://localhost:8501
```

#### Production Docker Deployment
```bash
# Build for production
docker build -t ai-content-detector:prod .

# Run with proper resource limits
docker run -d \
  --name ai-detector-prod \
  --memory=4g \
  --cpus=2 \
  -p 8000:8000 \
  --restart=unless-stopped \
  ai-content-detector:prod
```

### Cloud Deployment

#### AWS EC2
```bash
# 1. Launch EC2 instance (t3.large or better)
# 2. Install Docker
sudo yum update -y
sudo amazon-linux-extras install docker
sudo service docker start

# 3. Deploy application
git clone <repository>
cd ai_content_detector
sudo docker-compose up -d
```

#### Google Cloud Run
```bash
# 1. Build and push to Container Registry
gcloud builds submit --tag gcr.io/[PROJECT-ID]/ai-detector

# 2. Deploy to Cloud Run
gcloud run deploy --image gcr.io/[PROJECT-ID]/ai-detector \
  --platform managed \
  --memory 4Gi \
  --cpu 2
```

#### Azure Container Instances
```bash
# Create resource group
az group create --name ai-detector-rg --location eastus

# Deploy container
az container create \
  --resource-group ai-detector-rg \
  --name ai-detector \
  --image ai-content-detector:latest \
  --cpu 2 \
  --memory 4 \
  --ports 8000
```

## üìÅ File Structure & Functionality

### Root Directory
```
ai_content_detector/
‚îú‚îÄ‚îÄ README.md                 # Basic project documentation
‚îú‚îÄ‚îÄ PROJECT_GUIDE.md          # This comprehensive guide
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ setup.py                  # Package installation script
‚îú‚îÄ‚îÄ Dockerfile               # Docker container configuration
‚îú‚îÄ‚îÄ docker-compose.yml       # Multi-container orchestration
‚îú‚îÄ‚îÄ .gitignore               # Git ignore patterns
‚îî‚îÄ‚îÄ main                     # Entry point executable
```

### Core Source Code (`src/`)
```
src/
‚îú‚îÄ‚îÄ __init__.py              # Package initialization
‚îú‚îÄ‚îÄ text_detection/          # Text AI detection modules
‚îú‚îÄ‚îÄ image_detection/         # Image AI detection modules
‚îú‚îÄ‚îÄ preprocessing/           # Input preprocessing utilities
‚îî‚îÄ‚îÄ utils/                   # Shared utility functions
```

#### Text Detection Module (`src/text_detection/`)
- **`roberta_classifier.py`**: RoBERTa-based transformer classifier for text detection
  - Fine-tuned RoBERTa model for AI text classification
  - Handles tokenization and inference
  - Confidence scoring and prediction logic

- **`perplexity_analyzer.py`**: GPT-2 based perplexity analysis
  - Calculates text perplexity using GPT-2
  - Lower perplexity often indicates AI-generated text
  - Sliding window analysis for long texts

- **`burstiness_analyzer.py`**: Sentence variance and burstiness detection
  - Analyzes sentence length variation patterns
  - Measures text "burstiness" characteristics
  - Human text typically has higher burstiness

- **`text_ensemble.py`**: Combines multiple text detection methods
  - Ensemble model combining RoBERTa, perplexity, and burstiness
  - Weighted voting system for final predictions
  - Confidence calibration and threshold optimization

#### Image Detection Module (`src/image_detection/`)
- **`efficientnet_classifier.py`**: EfficientNet-based CNN classifier
  - Pre-trained EfficientNet fine-tuned for AI image detection
  - Handles image preprocessing and normalization
  - Feature extraction and classification

- **`frequency_cnn.py`**: Frequency domain analysis CNN
  - Operates on frequency/spectral domain features
  - Detects frequency artifacts common in AI-generated images
  - DCT and FFT-based feature extraction

- **`prnu_detector.py`**: Photo Response Non-Uniformity detection
  - Analyzes sensor noise patterns
  - Real cameras have unique PRNU fingerprints
  - AI-generated images lack authentic PRNU patterns

- **`image_ensemble.py`**: Combines multiple image detection methods
  - Ensemble of EfficientNet, Frequency CNN, and PRNU
  - Multi-level feature fusion
  - Confidence scoring and final prediction

### API Backend (`api/`)
```
api/
‚îú‚îÄ‚îÄ __init__.py              # API package initialization
‚îî‚îÄ‚îÄ main.py                  # FastAPI application and endpoints
```

#### `api/main.py` - Main API Application
- **FastAPI Application Setup**: CORS, middleware, documentation
- **Model Loading**: Lazy loading of text and image ensembles
- **Health Endpoints**: `/health`, `/ready` for monitoring
- **Detection Endpoints**:
  - `POST /detect/text` - Text AI detection
  - `POST /detect/image` - Image AI detection
  - `POST /detect/batch` - Batch processing
- **Utility Endpoints**: Model info, statistics, performance metrics
- **Error Handling**: Comprehensive exception handling
- **Request Validation**: Pydantic models for input validation
- **Rate Limiting**: Built-in request rate limiting
- **Logging**: Structured logging for monitoring

### Web Interface (`ui/`)
```
ui/
‚îî‚îÄ‚îÄ app.py                   # Streamlit web application
```

#### `ui/app.py` - Streamlit Web Interface
- **Multi-page Application**: Text detection, image detection, batch processing
- **Interactive UI Components**:
  - Text input areas with real-time detection
  - Image upload with drag-and-drop support
  - Confidence visualization and charts
  - Detection history and analytics
- **Model Management**: Model loading status and configuration
- **Results Visualization**: Plotly charts for confidence scores
- **Export Functionality**: CSV/JSON export of results
- **Settings Panel**: Configuration options and model parameters

### Configuration (`config/`)
```
config/
‚îî‚îÄ‚îÄ config.yaml              # System configuration file
```

#### `config/config.yaml` - System Configuration
- **Model Settings**: Model names, weights, ensemble configurations
- **API Configuration**: Host, port, file size limits, rate limiting
- **Training Parameters**: Batch size, learning rate, epochs
- **Data Configuration**: Sample limits, preprocessing settings
- **Inference Settings**: Device selection, batch size, latency targets
- **Logging Configuration**: Log levels, formats, file paths
- **Path Configuration**: Model, data, logs, cache directories

### Scripts (`scripts/`)
```
scripts/
‚îú‚îÄ‚îÄ demo.py                  # Interactive demonstration script
‚îî‚îÄ‚îÄ evaluate_models.py       # Model evaluation and benchmarking
```

#### `scripts/demo.py` - Interactive Demo
- **Command-line Interface**: Interactive text and image testing
- **Sample Data**: Built-in examples for quick testing
- **Performance Metrics**: Response time and confidence reporting
- **Export Options**: Save results to files

#### `scripts/evaluate_models.py` - Model Evaluation
- **Benchmark Testing**: Comprehensive model evaluation
- **Dataset Support**: Multiple evaluation datasets
- **Metrics Calculation**: Accuracy, F1-score, precision, recall
- **Performance Analysis**: Latency and throughput testing
- **Report Generation**: Detailed evaluation reports

### Supporting Files

#### `requirements.txt` - Dependencies
- **Core ML Libraries**: PyTorch, Transformers, scikit-learn
- **Web Frameworks**: FastAPI, Streamlit, Uvicorn
- **Image Processing**: OpenCV, PIL, NumPy
- **Utilities**: Pandas, Requests, python-dotenv
- **Development Tools**: pytest, black, flake8

#### `Dockerfile` - Container Configuration
- **Base Image**: Python 3.10 slim
- **System Dependencies**: Required system packages
- **Python Dependencies**: Requirements installation
- **Application Setup**: Code copying and permissions
- **Runtime Configuration**: Port exposure and startup command

#### `docker-compose.yml` - Multi-container Setup
- **API Service**: FastAPI backend container
- **UI Service**: Streamlit frontend container
- **Volume Mounts**: Persistent storage for models and data
- **Network Configuration**: Service communication
- **Health Checks**: Container health monitoring

## üîå API Documentation

### Authentication
No authentication required for basic usage. Rate limiting applies.

### Base URL
- Local: `http://localhost:8000`
- Production: `https://your-domain.com`

### Endpoints

#### Health Check
```bash
GET /health
# Response: {"status": "healthy", "timestamp": "2024-01-01T12:00:00Z"}

GET /ready
# Response: {"status": "ready", "models_loaded": true}
```

#### Text Detection
```bash
POST /detect/text
Content-Type: application/json

{
  "text": "Your text content here",
  "options": {
    "return_probabilities": true,
    "detailed_analysis": false
  }
}

# Response:
{
  "is_ai": true,
  "confidence": 0.87,
  "probabilities": {
    "human": 0.13,
    "ai": 0.87
  },
  "processing_time": 245,
  "model_version": "1.0.0"
}
```

#### Image Detection
```bash
POST /detect/image
Content-Type: multipart/form-data

# Form data:
# image: [file upload]
# options: {"return_probabilities": true}

# Response:
{
  "is_ai": false,
  "confidence": 0.92,
  "probabilities": {
    "human": 0.92,
    "ai": 0.08
  },
  "processing_time": 156,
  "image_info": {
    "width": 1024,
    "height": 768,
    "format": "JPEG"
  }
}
```

#### Batch Processing
```bash
POST /detect/batch
Content-Type: application/json

{
  "items": [
    {"type": "text", "content": "Text 1"},
    {"type": "text", "content": "Text 2"}
  ],
  "options": {
    "parallel": true,
    "return_detailed": false
  }
}
```

## ‚öôÔ∏è Configuration

### Environment Variables
```bash
# Model configuration
AI_DETECTOR_MODEL_PATH=/path/to/models
AI_DETECTOR_DEVICE=auto  # auto, cpu, cuda

# API configuration
AI_DETECTOR_HOST=0.0.0.0
AI_DETECTOR_PORT=8000
AI_DETECTOR_WORKERS=1

# Performance tuning
AI_DETECTOR_BATCH_SIZE=8
AI_DETECTOR_MAX_FILE_SIZE=10485760

# Logging
AI_DETECTOR_LOG_LEVEL=INFO
AI_DETECTOR_LOG_FILE=logs/ai_detector.log
```

### Configuration File (`config/config.yaml`)
Edit the configuration file to customize:
- Model parameters and weights
- API settings and limits
- Training hyperparameters
- Data processing options
- Logging configuration

## üîß Troubleshooting

### Common Issues

#### 1. Import Errors
```bash
# Error: ModuleNotFoundError
# Solution: Ensure virtual environment is activated and dependencies installed
pip install -r requirements.txt
```

#### 2. CUDA/GPU Issues
```bash
# Error: CUDA not available
# Solution: Install PyTorch with CUDA support or use CPU
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

#### 3. Memory Issues
```bash
# Error: OutOfMemoryError
# Solution: Reduce batch size in config
# Edit config/config.yaml: inference.batch_size: 4
```

#### 4. Model Loading Errors
```bash
# Error: Model files not found
# Solution: Ensure models directory exists and contains model files
mkdir -p models
# Download or copy model files to models/
```

#### 5. Port Already in Use
```bash
# Error: Port 8000 is already in use
# Solution: Use different port
uvicorn api.main:app --port 8001
```

#### 6. Permission Errors (Docker)
```bash
# Error: Permission denied
# Solution: Fix file permissions
sudo chown -R $(whoami):$(whoami) .
chmod +x scripts/*
```

### Performance Optimization

#### CPU Optimization
```bash
# Set environment variables for better CPU performance
export OMP_NUM_THREADS=4
export MKL_NUM_THREADS=4
```

#### GPU Optimization
```bash
# Enable GPU memory growth
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
```

#### Memory Management
```bash
# Reduce memory usage
export TRANSFORMERS_CACHE=./cache/transformers
export HF_HOME=./cache/huggingface
```

## üõ†Ô∏è Development Guide

### Setting Up Development Environment
```bash
# Install development dependencies
pip install -r requirements.txt
pip install -e .

# Install pre-commit hooks
pre-commit install

# Run tests
pytest tests/

# Format code
black src/ api/ ui/ scripts/
flake8 src/ api/ ui/ scripts/
```

### Adding New Models
1. Implement model class in appropriate detection module
2. Add model to ensemble configuration
3. Update config.yaml with model parameters
4. Add tests for new model
5. Update documentation

### API Development
```bash
# Run API in development mode with auto-reload
uvicorn api.main:app --reload --port 8000

# View API documentation
# http://localhost:8000/docs
```

### UI Development
```bash
# Run Streamlit in development mode
streamlit run ui/app.py --server.runOnSave true
```

### Testing
```bash
# Run all tests
pytest

# Run specific test categories
pytest tests/unit/
pytest tests/integration/
pytest tests/performance/

# Generate coverage report
pytest --cov=src --cov-report=html
```

### Building and Publishing
```bash
# Build package
python setup.py sdist bdist_wheel

# Build Docker image
docker build -t ai-content-detector:latest .

# Tag for registry
docker tag ai-content-detector:latest your-registry/ai-content-detector:v1.0.0
```

## üìû Support and Contact

For issues, questions, or contributions:
- Check existing issues and documentation
- Create detailed bug reports with logs
- Include system information and steps to reproduce
- For feature requests, describe use case and requirements

---

**Note**: This guide covers the complete setup and usage of the AI Content Detection System. For specific technical details about individual models or algorithms, refer to the source code documentation and comments within each module.